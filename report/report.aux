\relax 
\catcode `"\active 
\providecommand*\new@tpo@label[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{danish}{}
\babel@aux{danish}{}
\babel@aux{english}{}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of a weighting $a_{ij}$.}}{2}}
\newlabel{fig:weightings}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{footprints2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of the SIRT algorithm.}}{4}}
\newlabel{fig:sirt}{{2}{4}}
\citation{natterer2001}
\citation{Gao2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Computing the projection matrix}{5}}
\newlabel{sysmat}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A looped version of the projection matrix algorithm.}}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Nested parallel version}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A looped version of the forward projection, where the raysperstep should be the largest number possible such that the computations fit in the memory. $step*raysperstep$ should equal the total number of rows.}}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Flattening}{7}}
\citation{*}
\bibstyle{plain}
\bibdata{gpu}
\bibcite{footprints2010}{1}
\bibcite{natterer2001}{2}
\bibcite{zhen2011}{3}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A looped version of the back projection, where the raysperstep should be the largest number possible such that the computations fit in the memory. $step*raysperstep$ should equal the total number of rows.}}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Comparison to a CUDA implementation}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Memory coalescence and other optimization ideas}{8}}
