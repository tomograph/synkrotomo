\relax 
\catcode `"\active 
\providecommand*\new@tpo@label[2]{}
\providecommand \oddpage@label [2]{}
\babel@aux{danish}{}
\babel@aux{danish}{}
\babel@aux{english}{}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of a weighting $a_{ij}$.}}{2}}
\newlabel{fig:weightings}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\citation{footprints2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of the SIRT algorithm.}}{4}}
\newlabel{fig:sirt}{{2}{4}}
\citation{natterer2001}
\citation{Gao2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Computing the projection matrix}{5}}
\newlabel{sysmat}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A looped version of the projection matrix algorithm.}}{6}}
\newlabel{sysmatcompare}{{2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A lcomparison of the projection matrix algorithms run for gridsizes 64 to 256. Since the universities GPUs only have about 3GB of memory this was the largest size we could run for without chunking up the matrix.}}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Nested parallel forward and back projctions}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces A looped version of the forward projection, where the raysperstep should be chosen such that the computations fit in the memory. $step*raysperstep$ should equal the total number of rows.}}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces A looped version of the back projection, where the raysperstep should be the largest number possible such that the computations fit in the memory. $step*raysperstep$ should equal the total number of rows.}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Flattening and other optimization attempts}{10}}
\newlabel{fpcompare}{{4}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces A comparison of the forward projections run with different matrix implementations and the version where the forward projection is integrated in projectiomatrix\_doubleparallel. The chunk size was 32. As expected the semiflat version performed rather badly. The implementation using the double parallel version performed best. The rest of the algorithms are nested, using different projection matrix algorithms inside.}}{11}}
\citation{*}
\bibstyle{plain}
\bibdata{gpu}
\bibcite{Gao2012}{1}
\bibcite{footprints2010}{2}
\bibcite{natterer2001}{3}
\bibcite{zhen2011}{4}
\@writefile{toc}{\contentsline {section}{\numberline {5}Comparison to a CUDA implementation}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Memory coalescence and other optimization ideas}{12}}
