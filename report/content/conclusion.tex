\section{Conclusion}
We set out to make a parallel implementation of forward and back projection for algebraic tomographic reconstruction. We found that most of the time spend in our initial nested versions, using code from a bachelor project for generating the system matrix, was spend on calculating the matrix. We therefore concentrated on improving the code for calcualting the matrix. We managed to get a slight speedup of about 1.3 times compared to the code from the bachelor project by exploiting a second level of parallelism. When we compare a c compiled version of our futhark code with an opencl compiled version we get a speedup of about 1.3. Strangely enough our c compiled code actually runs slightly faster than the opencl compiled version of the code from the bachelor project. It therefore seems that our new version is better both sequentially and in parallel.\\
We attempted to compare our implementations with those in a python library called astra toolbox with a backend implemented in CUDA. However, we did not time the kernels only, but timed the call from python which has significant overhead. Therefore, it is difficult to compare. The results we got differed on which function was run first, and generally seemed to vary a lot. To properly time the functions, we would need to go to the astra code an time the kernel only. It seems to perform better than our versions though, and it would be nice to compare the CUDA code with the opencl compiled versions from futhark.\\
Some of our code may benefit from upcoming block and register tiling in futhark, or streaming possibilities as memory seems to be the biggest limitation. Other possibilities for optimizations could be to consider other datastructures for more sparse storage, or investigate how much precision is needed for good reconstructions. It will also be worth it to look at the branching in the kernels. Flattening does not seem very promising since we already have memory issues and our semiflat versions performed rather badly. Perhaps if the computation of the system matrix was also sparse and flat we would see an improvement. \\
Overall we were happy to get a slight speedup for the matrix computations, and there is still lots of work that could be done on this project. We look forward to keep working on it with new upcoming features in futhark and to have time to scour the compiled code for further optimizations.
